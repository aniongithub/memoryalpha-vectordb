#! /usr/bin/env python3


import os
from lxml import etree
import mwparserfromhell
import re
from concurrent.futures import ThreadPoolExecutor
from threading import Lock
import multiprocessing
import requests
from urllib.parse import quote, unquote
import hashlib
from pathlib import Path
from sentence_transformers import SentenceTransformer
from PIL import Image
import numpy as np

import sys
import pysqlite3
sys.modules["sqlite3"] = pysqlite3

import chromadb
from chromadb.config import Settings

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
# Adjust paths relative to the script directory
INPUT_XML = os.path.join(SCRIPT_DIR, "../data/enmemoryalpha_pages_current.xml") # Path to the db .xml file
OUTPUT_DIR = os.path.join(SCRIPT_DIR, "../data")
os.makedirs(OUTPUT_DIR, exist_ok=True)

CHROMA_DB_DIR = os.path.join(SCRIPT_DIR, "../data/enmemoryalpha_db")
IMAGES_DIR = os.path.join(SCRIPT_DIR, "../data/images")
os.makedirs(IMAGES_DIR, exist_ok=True)

MAX_PAGES = int(os.getenv("MAX_PAGES", -1)) # Get the max pages to process from the environment and cast to int

# Global variables for thread coordination
collection_lock = Lock()
count_lock = Lock()
download_lock = Lock()
embedding_lock = Lock()
global_count = 0
downloaded_images = set()  # Track downloaded images to avoid duplicates
clip_model = None  # Will be initialized once
text_model = None  # Will be initialized once

def initialize_clip_model():
    """Initialize the CLIP model once, using a fast image processor"""
    global clip_model
    if clip_model is None:
        print("ü§ñ Loading CLIP model...")
        clip_model = SentenceTransformer('clip-ViT-B-32', tokenizer_kwargs={'use_fast': True})
        print("‚úÖ CLIP model loaded")
    return clip_model

def initialize_text_model():
    """Initialize the all-MiniLM-L6-v2 model once"""
    global text_model
    if text_model is None:
        print("ü§ñ Loading all-MiniLM-L6-v2 model...")
        text_model = SentenceTransformer('all-MiniLM-L6-v2')
        print("‚úÖ MiniLM model loaded")
    return text_model

def generate_image_embedding(image_path):
    """Generate CLIP embedding for an image"""
    try:
        model = initialize_clip_model()
        # Skip SVG files as PIL can't handle them well
        if image_path.lower().endswith('.svg'):
            print(f"‚ö†Ô∏è  Skipping SVG file: {image_path}")
            return None
        image = Image.open(image_path).convert('RGB')
        with embedding_lock:
            embedding = model.encode(image)
        return embedding.tolist()  # Convert numpy array to list for JSON serialization
    except Exception as e:
        print(f"‚ö†Ô∏è  Error generating embedding for {image_path}: {e}")
        return None

def generate_text_embedding(text):
    """Generate MiniLM embedding for text"""
    try:
        model = initialize_text_model()
        with embedding_lock:
            embedding = model.encode(text)
        return embedding.tolist()
    except Exception as e:
        print(f"‚ö†Ô∏è  Error generating text embedding: {e}")
        return None

def extract_image_references(wikitext):
    """Extract image references from MediaWiki markup"""
    images = []
    try:
        parsed = mwparserfromhell.parse(wikitext)
        for wikilink in parsed.filter_wikilinks():
            title = str(wikilink.title).strip()
            if title.lower().startswith(('file:', 'image:')):
                # Remove namespace prefix
                image_name = title[5:] if title.lower().startswith('file:') else title[6:]
                images.append(image_name)
        
        # Also look for direct image references in templates
        for template in parsed.filter_templates():
            for param in template.params:
                param_value = str(param.value).strip()
                if param_value.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.svg', '.webp')):
                    images.append(param_value)
    except Exception as e:
        print(f"‚ö†Ô∏è  Error extracting images: {e}")
    
    return list(set(images))  # Remove duplicates

def download_image(image_name, images_dir):
    """Download an image from Memory Alpha and save it locally"""
    global downloaded_images
    
    # Create a safe filename
    safe_name = re.sub(r'[^a-zA-Z0-9._-]', '_', image_name)
    local_path = os.path.join(images_dir, safe_name)
    
    # Check if already downloaded
    with download_lock:
        if safe_name in downloaded_images:
            return local_path, None  # Return None for URL since we don't know which worked
        downloaded_images.add(safe_name)
    
    try:
        # Skip external URLs (not hosted on Memory Alpha)
        if image_name.startswith(('http://', 'https://')):
            print(f"‚ö†Ô∏è  Skipping external URL: {image_name}")
            return None, None
            
        # Memory Alpha uses the standard MediaWiki file URL structure
        # First, we need to encode the filename properly
        encoded_name = quote(image_name.replace(' ', '_'))
        
        # Try multiple URL patterns for Memory Alpha
        url_patterns = [
            f"https://memory-alpha.fandom.com/wiki/Special:FilePath/{encoded_name}",
            f"https://static.wikia.nocookie.net/memoryalpha/images/{encoded_name}",
        ]
        
        for image_url in url_patterns:
            try:
                # Download the image
                response = requests.get(image_url, timeout=30, stream=True)
                if response.status_code == 200:
                    with open(local_path, 'wb') as f:
                        for chunk in response.iter_content(chunk_size=8192):
                            f.write(chunk)
                    return local_path, image_url  # Return the working URL
                elif response.status_code == 404:
                    continue  # Try next URL pattern
                else:
                    print(f"‚ö†Ô∏è  HTTP {response.status_code} for {image_url}")
                    continue
            except requests.RequestException as e:
                print(f"‚ö†Ô∏è  Request error for {image_url}: {e}")
                continue
        
        print(f"‚ö†Ô∏è  Failed to download image {image_name}: No working URL found")
        return None, None
            
    except Exception as e:
        print(f"‚ö†Ô∏è  Error downloading image {image_name}: {e}")
        return None, None

def process_page(page_elem):
    """Process a single page element and return the processed data"""
    title_elem = page_elem.find("{http://www.mediawiki.org/xml/export-0.11/}title")
    title = title_elem.text if title_elem is not None else ""
    text_elem = page_elem.find(".//{http://www.mediawiki.org/xml/export-0.11/}text")
    raw_text = text_elem.text if text_elem is not None else ""

    # Skip unwanted pages
    if not raw_text or raw_text.strip().lower().startswith("#redirect"):
        return None
    if (title.lower().startswith(("file:", "user:", "talk:", "user talk:", 
                                 "memory alpha:", "memory alpha talk:", 
                                 "mediawiki:", "mediawiki talk:", "template:", 
                                 "template talk:", "category:", "category talk:"))):
        return None
    
    # Extract image references before parsing
    image_references = extract_image_references(raw_text)
    downloaded_image_paths = []
    
    # Download images and generate embeddings
    for image_name in image_references[:5]:  # Limit to 5 images per page to avoid overwhelming
        try:
            image_path, actual_url = download_image(image_name, IMAGES_DIR)
            if image_path and os.path.exists(image_path):
                # Generate embedding
                embedding = generate_image_embedding(image_path)
                if embedding:
                    # Use the actual working URL or fallback to Special:FilePath
                    if not actual_url:
                        encoded_name = quote(image_name.replace(' ', '_'))
                        actual_url = f"https://memory-alpha.fandom.com/wiki/Special:FilePath/{encoded_name}"
                    
                    downloaded_image_paths.append({
                        'name': image_name,
                        'url': actual_url,  # Store the actual working URL
                        'embedding': embedding,
                        'local_path': image_path  # Keep for now, will delete after processing
                    })
                
                # Delete the local image file to save space
                try:
                    if os.path.exists(image_path):
                        os.remove(image_path)
                except Exception as e:
                    print(f"‚ö†Ô∏è  Error deleting image {image_path}: {e}")
                    
        except Exception as e:
            print(f"‚ö†Ô∏è  Error processing image {image_name}: {e}")
            continue
    
    try:
        clean_text = mwparserfromhell.parse(raw_text).strip_code().strip()
    except Exception as e:
        print(f"‚ö†Ô∏è  Error parsing {title}: {e}")
        return None
    
    if len(clean_text) < 500:
        return None

    # Return the processed data with image information
    return {
        'title': title,
        'clean_text': clean_text,
        'images': downloaded_image_paths
    }

def add_batch_to_collections(text_collection, image_collection, batch_data):
    """Add a batch of processed data to separate ChromaDB collections"""
    global global_count

    batch_docs = []
    batch_metadatas = []
    batch_ids = []
    batch_embeddings = []

    image_docs = []
    image_metadatas = []
    image_ids = []
    image_embeddings = []

    with count_lock:
        for data in batch_data:
            # Add text document
            base_id = re.sub(r'[^a-zA-Z0-9_\-]', '_', data['title'])[:48] or "untitled"
            safe_id = f"{base_id}_{global_count}"
            batch_ids.append(safe_id)
            batch_docs.append(data['clean_text'])
            # Generate text embedding
            text_embedding = generate_text_embedding(data['clean_text'])
            batch_embeddings.append(text_embedding)

            images = data.get('images', [])
            metadata = {
                "title": data['title'],
                "content_type": "text",
                "image_count": len(images),
                "image_names": "; ".join([img['name'] for img in images]) if images else ""
            }
            batch_metadatas.append(metadata)
            global_count += 1

            # Add separate documents for each image
            for img in images:
                if img.get('embedding'):
                    img_id = f"{base_id}_img_{global_count}"
                    image_ids.append(img_id)
                    image_doc = f"Image: {img['name']} from page '{data['title']}'"
                    image_docs.append(image_doc)
                    img_metadata = {
                        "title": f"Image: {img['name']}",
                        "content_type": "image",
                        "source_page": data['title'],
                        "image_name": img['name'],
                        "image_url": img['url']
                    }
                    image_metadatas.append(img_metadata)
                    image_embeddings.append(img['embedding'])
                    global_count += 1

    # Add text documents to text collection
    with collection_lock:
        if batch_docs:
            text_collection.add(documents=batch_docs, metadatas=batch_metadatas, ids=batch_ids, embeddings=batch_embeddings)
        # Add image documents to image collection
        if image_docs:
            image_collection.add(documents=image_docs, metadatas=image_metadatas, ids=image_ids, embeddings=image_embeddings)

    return len(batch_data), len(image_docs)

def extract_and_store_chromadb(xml_path, chroma_db_dir, max_pages = -1):
    global global_count
    global_count = 0

    # Initialize models early
    clip_model = initialize_clip_model()
    text_model = initialize_text_model()

    # Set up ChromaDB persistent client and collections
    client = chromadb.PersistentClient(path=chroma_db_dir, settings=Settings(allow_reset=True))
    from chromadb.utils import embedding_functions

    # CLIP embedding function for images
    class CLIPEmbeddingFunction(embedding_functions.EmbeddingFunction):
        def __call__(self, input):
            embeddings = []
            for text in input:
                with embedding_lock:
                    embedding = clip_model.encode(text)
                embeddings.append(embedding.tolist())
            return embeddings

    # MiniLM embedding function for text
    class MiniLMEmbeddingFunction(embedding_functions.EmbeddingFunction):
        def __call__(self, input):
            embeddings = []
            for text in input:
                with embedding_lock:
                    embedding = text_model.encode(text)
                embeddings.append(embedding.tolist())
            return embeddings

    clip_ef = CLIPEmbeddingFunction()
    minilm_ef = MiniLMEmbeddingFunction()

    # Create or reset collections
    try:
        try:
            client.delete_collection("memoryalpha_text")
            print("üóëÔ∏è  Deleted existing text collection")
        except:
            pass
        try:
            client.delete_collection("memoryalpha_images")
            print("üóëÔ∏è  Deleted existing image collection")
        except:
            pass
        text_collection = client.create_collection("memoryalpha_text", embedding_function=minilm_ef)
        image_collection = client.create_collection("memoryalpha_images", embedding_function=clip_ef)
        print("üìö Created new ChromaDB collections for text and images")
    except Exception as e:
        print(f"‚ö†Ô∏è  Error creating collections: {e}")
        text_collection = client.get_collection("memoryalpha_text", embedding_function=minilm_ef)
        image_collection = client.get_collection("memoryalpha_images", embedding_function=clip_ef)
        print("üìö Using existing ChromaDB collections for text and images")

    num_workers = multiprocessing.cpu_count()
    print(f"üöÄ Using {num_workers} worker threads for processing")

    context = etree.iterparse(xml_path, tag="{http://www.mediawiki.org/xml/export-0.11/}page", events=("end",), recover=True)

    BATCH_SIZE = 100
    PROCESSING_BATCH_SIZE = num_workers * 4

    page_batch = []
    total_processed = 0
    total_image_docs = 0

    with ThreadPoolExecutor(max_workers=num_workers) as executor:
        for _, elem in context:
            page_batch.append(elem)
            if len(page_batch) >= PROCESSING_BATCH_SIZE:
                future_results = [executor.submit(process_page, page) for page in page_batch]
                processed_data = []
                for future in future_results:
                    result = future.result()
                    if result:
                        processed_data.append(result)
                while processed_data:
                    current_batch = processed_data[:BATCH_SIZE]
                    processed_data = processed_data[BATCH_SIZE:]
                    if current_batch:
                        added_count, added_images = add_batch_to_collections(text_collection, image_collection, current_batch)
                        total_processed += added_count
                        total_image_docs += added_images
                        print(f"üìÑ Processed {total_processed} pages, {total_image_docs} image documents, downloaded {len(downloaded_images)} unique images...")
                for page in page_batch:
                    page.clear()
                page_batch = []
                if max_pages != -1 and total_processed >= max_pages:
                    break
        if page_batch and (max_pages == -1 or total_processed < max_pages):
            future_results = [executor.submit(process_page, page) for page in page_batch]
            processed_data = []
            for future in future_results:
                result = future.result()
                if result:
                    processed_data.append(result)
            if max_pages != -1:
                remaining = max_pages - total_processed
                processed_data = processed_data[:remaining]
            while processed_data:
                current_batch = processed_data[:BATCH_SIZE]
                processed_data = processed_data[BATCH_SIZE:]
                if current_batch:
                    added_count, added_images = add_batch_to_collections(text_collection, image_collection, current_batch)
                    total_processed += added_count
                    total_image_docs += added_images
            for page in page_batch:
                page.clear()

    print(f"‚úÖ Extracted and stored {total_processed} pages and {total_image_docs} image documents in ChromaDB at: {chroma_db_dir}")
    print(f"üñºÔ∏è  Processed {len(downloaded_images)} unique images with CLIP embeddings")

# Run it
extract_and_store_chromadb(INPUT_XML, CHROMA_DB_DIR, MAX_PAGES)
